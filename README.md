# JLP_Segmenter
JLP的中文分词工具(不断更新中)

基于1998人民日报语料和jieba分词的核心语料，
目前实现了前后向最大匹配、一元最大概率分词、一二元插值最大概率分词，
后续会实现更加复杂的模型。

测试文件见test3文件，里面包括了100句来自于人民日报的句子，切分结果见output.txt。
